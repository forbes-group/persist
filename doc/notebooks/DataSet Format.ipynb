{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#Archives-and-DataSets\" data-toc-modified-id=\"Archives-and-DataSets-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Archives and DataSets</a></div><div class=\"lev1 toc-item\"><a href=\"#Archive-Format\" data-toc-modified-id=\"Archive-Format-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Archive Format</a></div><div class=\"lev2 toc-item\"><a href=\"#Containers-and-Duplicates\" data-toc-modified-id=\"Containers-and-Duplicates-21\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Containers and Duplicates</a></div><div class=\"lev2 toc-item\"><a href=\"#External-Data\" data-toc-modified-id=\"External-Data-22\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>External Data</a></div><div class=\"lev2 toc-item\"><a href=\"#Examples\" data-toc-modified-id=\"Examples-23\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Examples</a></div><div class=\"lev3 toc-item\"><a href=\"#Non-scoped-(flat)-Format\" data-toc-modified-id=\"Non-scoped-(flat)-Format-231\"><span class=\"toc-item-num\">2.3.1&nbsp;&nbsp;</span>Non-scoped (flat) Format</a></div><div class=\"lev3 toc-item\"><a href=\"#Scoped-Format\" data-toc-modified-id=\"Scoped-Format-232\"><span class=\"toc-item-num\">2.3.2&nbsp;&nbsp;</span>Scoped Format</a></div><div class=\"lev3 toc-item\"><a href=\"#External-Data\" data-toc-modified-id=\"External-Data-233\"><span class=\"toc-item-num\">2.3.3&nbsp;&nbsp;</span>External Data</a></div><div class=\"lev1 toc-item\"><a href=\"#DataSet-Format\" data-toc-modified-id=\"DataSet-Format-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>DataSet Format</a></div><div class=\"lev2 toc-item\"><a href=\"#Caveats\" data-toc-modified-id=\"Caveats-31\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Caveats</a></div><div class=\"lev1 toc-item\"><a href=\"#Examples\" data-toc-modified-id=\"Examples-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Examples</a></div><div class=\"lev2 toc-item\"><a href=\"#External-Data\" data-toc-modified-id=\"External-Data-41\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>External Data</a></div><div class=\"lev1 toc-item\"><a href=\"#The-DS-Format\" data-toc-modified-id=\"The-DS-Format-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>The DS Format</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Archives and DataSets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two main classes provided by the `persist` module: `persist.Archive` and `persist.DataSet`.  Archives deal with the linkage between objects so that if multiple objects are referred to, they are only stored once in the archive.  Archives provide a way to serialize the data with the `str()` operator, but are not well suited for saving data to disk.\n",
    "\n",
    "DataSets use archives, but provide additional functionality for saving the data to disk for true persistence.  This document describes the format of this data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Archive Format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `persist.Archive` object maintains a collection of python objects that are inserted with `persist.Archive.insert()`.  The main purpose of an archive is to provide an executable string which can be evaluated to regenerate the objects that have been inserted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Containers and Duplicates\n",
    "\n",
    "The main complexity with archives is with containers – all object referenced in a contain (like a  list or dictionary) need to be inserted into the archive, and inserted only once."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## External Data\n",
    "\n",
    "A second complexity is that we allow large arrays (whose size exceeds `array_threshold`) to be stored externally.  To deal with these, the archive expects the string representation to be evaluated in an environment that has these arrays defined so that they can be inserted appropriately as needed into containers.  The behavior is controlled by the following attributes of `persist.Archive`:\n",
    "\n",
    "* `array_threshold` : Arrays longer than this will be stored as external data.  Shorter arrays will be stored in the archive.\n",
    "* `data_name` : When evaluated, the environment should contain a dictionary with this name (default `'_arrays'`) which contains all of the externally stored arrays (or placeholders).\n",
    "\n",
    "* `datafile` : The name of the file or directory in which external arrays will be stored.\n",
    "* `data_format` : The format in which external arrays will be stored.\n",
    "\n",
    "A downside of the current implementation is that all of the arrays need to be loaded in order for the archive to be evaluated.  This complicates delayed loading of large arrays unless a placeholder can be used that only loads the data when used.  Both HDF5 and NumPy support this (via [memmap_mode](https://docs.scipy.org/doc/numpy/reference/generated/numpy.load.html#numpy.load)) but it is not implemented yet.  As a workaround, separate archives should be used for external arrays.  This is the approach that `DataSet` takes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we demonstrate a simple archive containing all of the data.  We start with the simplest format which is obtained with `scoped=False`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-scoped (flat) Format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with the `scoped=False` format.  This produces a flat archive that is easier to read:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.57 ms, sys: 68 µs, total: 1.64 ms\n",
      "Wall time: 1.65 ms\n",
      "import numpy as _numpy\n",
      "a = 1\n",
      "_g3 = [a, 2, 3]\n",
      "x = _numpy.fromstring('\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00', dtype='<i8').reshape((2,))\n",
      "b = [x, _g3, _g3]\n",
      "del _numpy\n",
      "del _g3\n",
      "try: del __builtins__\n",
      "except NameError: pass\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "import tempfile\n",
    "import shutil\n",
    "import numpy as np\n",
    "import persist.archive;reload(persist.archive)\n",
    "from persist.archive import Archive\n",
    "tmpdir = tempfile.mkdtemp()  # Make temporary directory for dataset\n",
    "\n",
    "a = 1\n",
    "x = np.arange(2)\n",
    "y = np.arange(3)  # Implicitly reference in archive\n",
    "y = [1,2,3]\n",
    "b = [x, y, y]     # Nested references to x and y\n",
    "\n",
    "archive = Archive(scoped=False)\n",
    "archive.insert(a=a, x=x, b=b)\n",
    "\n",
    "# Get the string representation\n",
    "%time s = str(archive)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that intermediate objects not explicitly inserted are stored with variables like `_g#` and that these are deleted, so that evaluating the string in a dictionary gives a clean result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 1, 'b': [array([0, 1]), [1, 2, 3], [1, 2, 3]], 'x': array([0, 1])}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now execute the representation to get the data\n",
    "d = {}\n",
    "exec(s, d)\n",
    "print(d)\n",
    "d['b'][1] is d['b'][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The potential problem with the flat format is that to obtain this simple representation, a graph reduction is performed that replaces intermediate nodes, ensuring that local variables do not have name clashes as well as simplifing the representation.  Replacing variables in representations can have performance implications if the objects are large.  The fastest approach is a string replacement, but this can make mistakes if the substring appears in data.  The option `robust_replace` invokes the python AST parser, but this is slower."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoped Format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To alleviate these issues, the `scoped=True` format is provided.  This is visually much more complicated as each object is constructed in a function.  The advantage is that this provides a local scope in which objects are defined.  As a result, any local variables defined in the representation of the object can be used as they are without worrying that they will conflict with other names in the file.  No reduction is performed and no replacements are made, makeing the method faster and more robust, but less attractive if the files need to be inspected by humans:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 713 µs, sys: 230 µs, total: 943 µs\n",
      "Wall time: 778 µs\n",
      "_g5 = 3\n",
      "_g4 = 2\n",
      "a = 1\n",
      "\n",
      "def _g3(_l_0=a,_l_1=_g4,_l_2=_g5):\n",
      "    return [_l_0, _l_1, _l_2]\n",
      "_g3 = _g3()\n",
      "\n",
      "def x():\n",
      "    import numpy as numpy\n",
      "    return numpy.fromstring('\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00', dtype='<i8').reshape((2,))\n",
      "x = x()\n",
      "\n",
      "def b(_l_0=x,_l_1=_g3,_l_2=_g3):\n",
      "    return [_l_0, _l_1, _l_2]\n",
      "b = b()\n",
      "del _g5, _g4, _g3\n",
      "try: del __builtins__\n",
      "except NameError: pass\n"
     ]
    }
   ],
   "source": [
    "archive = Archive(scoped=True)\n",
    "archive.insert(a=a, x=x, b=b)\n",
    "\n",
    "# Get the string representation\n",
    "%time s = str(archive)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### External Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we store an array that exceeds the array threshold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import numpy as _numpy\n",
      "a = 1\n",
      "_g4 = [a, 2, 3]\n",
      "b = [_numpy.fromstring('\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00', dtype='<i8').reshape((2,)), _g4, _g4]\n",
      "x = _arrays['array_0']\n",
      "del _numpy\n",
      "del _g4\n",
      "try: del __builtins__\n",
      "except NameError: pass\n"
     ]
    }
   ],
   "source": [
    "archive = Archive(scoped=False, datafile='tmpdata', array_threshold=3)\n",
    "x = np.arange(10)\n",
    "archive.insert(a=a, x=x, b=b)\n",
    "s = str(archive)\n",
    "print s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data for `x` is stored in a separate file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array_0.npy\r\n"
     ]
    }
   ],
   "source": [
    "!ls $archive.datafile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate this archive, we must first load the arrays and provide these in the execution environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_arrays': {'array_0': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])},\n",
       " 'a': 1,\n",
       " 'b': [array([0, 1]), [1, 2, 3], [1, 2, 3]],\n",
       " 'x': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from persist.archive import load_arrays\n",
    "d = {archive.data_name: load_arrays(archive.datafile)}\n",
    "exec(s, d)\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The convenience method `Archive.eval` does this for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1,\n",
       " 'b': [array([0, 1]), [1, 2, 3], [1, 2, 3]],\n",
       " 'x': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = Archive(datafile='tmpdata')\n",
    "a.eval(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!rm -rf tmpdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataSet Format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook outlines the format of a DataSet on disk.\n",
    "\n",
    "For this discussion, we shall assume that the dataset is stored in a directory called `dataset`.  This DataSet directory contains the following files\n",
    "\n",
    "* `_this_dir_is_a_DataSet`: This is an empty file signifying that the directory is a DataSet.\n",
    "\n",
    "* `__init__.py`: Each DataSet is an importable python module so that the data can be used on a machine without the `persist` package.  This file contains all the data for and defines the following variable:\n",
    "  * `_info_dict`: This is a dictionary/namespace with string keys (which must be valid python identifiers) and associated data (which should in general be small).  These are intended to be interpreted as meta-data.\n",
    "  \n",
    "  In addition to `_info_dict`, the module may contain variables corresponding to the keys in `_info_dict` which are generally larger chunks of data and are not stored here (see below).  If the DataSet is directly imported, then `__init__.py` will attempt to load all of these arrays into memory.  (This behaviour may change in the future.)\n",
    "  \n",
    "  For the remainder of this discussion, we shall assume that `_info_dict` contains the key `'x'`.\n",
    "  \n",
    "* `x.py`: This is the python file responsible for loading the data associated with the key `'x'` in `_info_dict`. If the size of the array is less than the `array_threshold` specified in the `DataSet` object, then the data for the arrays are stored in this file, otherwise this file is responsible for loading the data from an associated file.\n",
    "\n",
    "* `data_x.*`: If the size of the array stored in `x` is larger than the `array_threshold`, then the data associated with `x` is stored in this file/directory which is either an HDF5 file or a numpy file.  This will be loaded by the file `x.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caveats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each attribute in a DataSet, such as `dataset.x` above, is an independent archive.  Thus, if the same data is stored under different names in a DataSet, then this data will be duplicated.  Each attribute, however, can be a full archive, so multiple copies of the same data within an object of the attribute will not be duplicated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storing dataset in /var/folders/m7/dnr91tjs4gn58_t3k8zp_g000000gp/T/tmpdAebTQ\n",
      "\u001b[34m.\u001b[m\u001b[m\n",
      "\u001b[34m..\u001b[m\u001b[m\n",
      "__init__.py\n",
      "_this_dir_is_a_DataSet\n",
      "a.py\n",
      "\u001b[34mdata_a\u001b[m\u001b[m\n",
      "\u001b[34mdata_x\u001b[m\u001b[m\n",
      "x.py\n",
      "['__init__.py', '_this_dir_is_a_DataSet', 'a.py', 'data_a', 'data_x', 'x.py']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mforbes/work/mmfbb/persist/persist/archive.py:1353: UserWarning: Data arrays ['array_0'] exist but no datafile specified. Save data manually and populate in _arrays dict.\n",
      "  \"Save data manually and populate in _arrays dict.\")\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "import tempfile\n",
    "import shutil\n",
    "import numpy as np\n",
    "import persist.archive;reload(persist.archive)\n",
    "from persist.archive import DataSet\n",
    "tmpdir = tempfile.mkdtemp()  # Make temporary directory for dataset\n",
    "print(\"Storing dataset in {}\".format(tmpdir))\n",
    "\n",
    "a = np.arange(10)\n",
    "x = np.arange(100)\n",
    "\n",
    "ds = DataSet(os.path.join(tmpdir, 'dataset'), 'w', array_threshold=20, data_format='npy')\n",
    "\n",
    "ds.a = a\n",
    "ds.x = x\n",
    "ds['a'] = \"A small array\"\n",
    "ds['x'] = \"A large array\"\n",
    "\n",
    "!ls -a1 $tmpdir/dataset\n",
    "print(os.listdir(os.path.join(tmpdir, 'dataset')))\n",
    "shutil.rmtree(tmpdir)        # Remove files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storing dataset in /var/folders/m7/dnr91tjs4gn58_t3k8zp_g000000gp/T/tmpcimdvb\n",
      "\u001b[34m.\u001b[m\u001b[m\n",
      "\u001b[34m..\u001b[m\u001b[m\n",
      "__init__.py\n",
      "_this_dir_is_a_DataSet\n",
      "a.py\n",
      "\u001b[34mdata_a\u001b[m\u001b[m\n",
      "\u001b[34mdata_x\u001b[m\u001b[m\n",
      "\u001b[34mdata_y\u001b[m\u001b[m\n",
      "x.py\n",
      "y.py\n",
      "['__init__.py', '_this_dir_is_a_DataSet', 'a.py', 'data_a', 'data_x', 'data_y', 'x.py', 'y.py']\n"
     ]
    }
   ],
   "source": [
    "tmpdir = tempfile.mkdtemp()  # Make temporary directory for dataset\n",
    "print(\"Storing dataset in {}\".format(tmpdir))\n",
    "\n",
    "a = np.arange(10)\n",
    "x = [np.arange(100)]\n",
    "y = x\n",
    "\n",
    "ds = DataSet(os.path.join(tmpdir, 'dataset'), 'w', array_threshold=20, data_format='npy')\n",
    "\n",
    "ds.a = a\n",
    "ds.x = x\n",
    "ds.y = y\n",
    "ds['a'] = \"A small array\"\n",
    "ds['x'] = \"A large array\"\n",
    "\n",
    "!ls -a1 $tmpdir/dataset\n",
    "print(os.listdir(os.path.join(tmpdir, 'dataset')))\n",
    "\n",
    "ds = DataSet(os.path.join(tmpdir, 'dataset'))\n",
    "shutil.rmtree(tmpdir)        # Remove files"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "66px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
